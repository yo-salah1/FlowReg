{"cells":[{"cell_type":"markdown","metadata":{"id":"f1_1-XLM_TB4"},"source":["# **Introduction**"]},{"cell_type":"markdown","source":["**How is this project different?**  \n","The word is flexibility, we have designed this pipeline so it can handle any regression dataset with just a few simple tweaks for data preprocessing.\n","\n","**Which model have we used?**  \n","All regression models we have learned throughout this training, the pipeline automatically finds the highest accuracy model and exports it as a .plk file.\n","\n","**Whats with flags?**  \n","We have introduced flags to our pipeline so you won't have to worry about changing the code just to drop some features, all you have to do is add those features to the drop_features flag and tada! problem solved!\n","\n","Some examples for our flags:  \n","- debug_mode -> Shows analytical information about the data, for example features dtypes and missing values\n","- skew_power -> Handles data skewness using the power method\n","- check_outliers -> Visualizes outliers in the data\n","\n","**What about the constants and models block?**  \n","It covers:\n","- Essential information like dataset path and target column name\n","- Some flags for automatic numerical/categorical feature selection\n","- Model selection"],"metadata":{"id":"oYXjt36VE8IX"}},{"cell_type":"markdown","metadata":{"id":"j082OXYBcTqW"},"source":["# **Import libraries**"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"tWajcOYxsWCG","executionInfo":{"status":"ok","timestamp":1756414594650,"user_tz":-180,"elapsed":25,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["\"\"\"\n","These are the needed libraries to run the project.\n","1- Core modules: are for reading data files, mathematical computations and data structuring.\n","2- Visualization modules: are needed to display plots, and heatmaps that are both needed for\n","   understanding the nature of the data and model evaluation.\n","3- Model splitting module: is needed to split data into training and testing.\n","4- Preprocessing modules: are needed to manipulate data, like encoding and scaling.\n","5- Regression modules: are needed for different regression models.\n","6- Evaulation modules: are needed for evaluation metrics like r2_score and root_mean_squared_error.\n","7- Pipeline & utility modules: are for file system handling and saving files.\n","\"\"\"\n","\n","# Core\n","import numpy as np\n","import pandas as pd\n","from scipy import stats\n","\n","# Visualization\n","from pandas.plotting import scatter_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Model selection / splitting\n","from sklearn.model_selection import train_test_split\n","\n","# Preprocessing\n","# Encoding\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","#Scaling\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import PowerTransformer\n","\n","# Regression models\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n","from xgboost import XGBRegressor\n","\n","#Evaluation\n","from sklearn.metrics import r2_score\n","\n","# Pipeline & utilities\n","import joblib\n","import os"]},{"cell_type":"markdown","metadata":{"id":"jocDY7FWkyYP"},"source":["# **Flags**"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"IxkXv1_KlXp7","executionInfo":{"status":"ok","timestamp":1756414594712,"user_tz":-180,"elapsed":52,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["\"\"\"Flags\"\"\"\n","# Analysis\n","debug_mode = False # sample / info / Missing / Duplicates / Describe\n","visualize_mode = False # Features distribution / Outliers / Skewness\n","\n","# Incorrect dtypes\n","check_dtypes = False # Checker\n","enforce_numerical = [] # Setter\n","\n","# Missing Values\n","check_missing = False # Checker\n","remove_missing = [\"Year\"] # Remover\n","fill_mean = [] # Imputer\n","fill_median = [] # Imputer\n","fill_mode = [] # Imputer\n","fill_ffill = [] # Imputer\n","fill_bfill = [] # Imputer\n","fill_constant = [] # Imputer\n","fill_constant_value = \"\" # Imputer, Give it a value if you have features in fill_constant\n","\n","# Outliers\n","check_outliers = False # Checker\n","outliers_zscore = [] # Remover\n","outliers_zscore_threshold = 2 # Remover, Give it a value if you have features in fill_constant\n","\n","# Scaling\n","check_scaling = False # Checker\n","standard_scale = [] # Scaler\n","min_max_scale = [] # Scaler\n","robust_scale = [] # Scaler\n","\n","# Skewness\n","check_skewness = False # Checker\n","skew_power = [] # Transformer, General, don't use with outliers\n","skew_log1p = [] # Transformer, Don't use with negative values\n","skew_cbrt = [] # Transformer, Don't use with high skew\n","\n","# Encoding\n","check_dtypes = False # Checker\n","label_encode = [\"Name\", \"Platform\", \"Genre\", \"Publisher\"] # Encoder\n","one_hot_encode = [] # Encoder\n","ordinal_encode = [] # Encoder\n","\n","# Feature engineering\n","check_correlation = False # Checker\n","corr_threshold = 0 # Remover, All results below this value will be dropped\n","drop_features = [] # Remover\n","\n","# Model deployment\n","do_save_model = True"]},{"cell_type":"markdown","metadata":{"id":"-a-wV3EllF5Z"},"source":["# **Constants & Models**"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"GZRCO9EyQ4M7","executionInfo":{"status":"ok","timestamp":1756414594717,"user_tz":-180,"elapsed":8,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["\"\"\"Constants\"\"\"\n","MODEL_PATH = \"test.plk\"\n","DATA_PATH = \"/content/video_games_sales.csv\"\n","TARGET = \"Global_Sales\"\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 42\n","\n","auto_select_numerical = True\n","auto_select_categorical = True\n","NUMERICAL_FEATURES = []\n","CATEGORICAL_FEATURES = []\n","\n","decision_tree_estimator = DecisionTreeRegressor(random_state=RANDOM_STATE)\n","\n","REGRESSION_MODELS = {\n","    \"LinearRegression\": LinearRegression(),\n","    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n","    \"SVR_rbf\": SVR(kernel=\"rbf\", C=1.0, epsilon=0.1),\n","    # \"SVR_linear\": SVR(kernel=\"linear\", C=1.0, epsilon=0.1),\n","    \"SVR_poly\": SVR(kernel=\"poly\", C=1.0, epsilon=0.1),\n","    \"SVR_sigmoid\": SVR(kernel=\"sigmoid\", C=1.0, epsilon=0.1),\n","    \"DecisionTree\": DecisionTreeRegressor(random_state=RANDOM_STATE , max_depth=5),\n","    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE),\n","    \"Bagging\": BaggingRegressor(estimator=decision_tree_estimator, n_estimators=50, random_state=RANDOM_STATE),\n","    \"AdaBoost\": AdaBoostRegressor(estimator=decision_tree_estimator, n_estimators=50, learning_rate=0.1, random_state=RANDOM_STATE),\n","    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE),\n","    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE),\n","}"]},{"cell_type":"markdown","metadata":{"id":"Ljgr3sjvu_FH"},"source":["# **Linear Regression Pipeline**"]},{"cell_type":"markdown","metadata":{"id":"GGY8WfgLerAP"},"source":["## **Data collection**"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"YERIR1ztseKQ","executionInfo":{"status":"ok","timestamp":1756414594720,"user_tz":-180,"elapsed":2,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def load_data():\n","    global NUMERICAL_FEATURES\n","    global CATEGORICAL_FEATURES\n","\n","    df = pd.read_csv(DATA_PATH)\n","\n","    if auto_select_numerical:\n","        NUMERICAL_FEATURES = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n","        print(\"Numerical features have been selected automatically\")\n","    if auto_select_categorical:\n","        CATEGORICAL_FEATURES = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n","        print(\"Categorical features have been selected automatically\")\n","\n","    print(\"Data has been loaded\")\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"knBtIcqXfIj_"},"source":["## **Data analysis & preprocessing**"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"G7a8i5kHfK4g","executionInfo":{"status":"ok","timestamp":1756414594745,"user_tz":-180,"elapsed":15,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def preprocessing(df):\n","    if enforce_numerical:\n","        df = enforce(df, enforce_numerical)\n","\n","    if label_encode or one_hot_encode or ordinal_encode:\n","        df = encode(df)\n","\n","    if skew_power or skew_log1p or skew_cbrt:\n","        df = skew(df)\n","\n","    if remove_missing or fill_mean or fill_median or fill_mode or fill_ffill or fill_bfill or fill_constant:\n","        df = handle_missing(df)\n","\n","    if outliers_zscore:\n","        df = handle_outliers(df)\n","\n","    if debug_mode:\n","        debug(df)\n","\n","    if visualize_mode:\n","        visualize(df)\n","\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"CQOo22ejBw2B"},"source":["### **Debug mode**"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"urT7TvmsAfYY","executionInfo":{"status":"ok","timestamp":1756414594777,"user_tz":-180,"elapsed":29,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def debug(df, debug_mode=False):\n","    if debug_mode:\n","        display(df.sample(10))\n","\n","    if debug_mode or check_dtypes:\n","        print(\"******\")\n","        print(\"Info:\")\n","        print(\"******\")\n","        print(df.info())\n","        print()\n","\n","    if debug_mode or check_missing:\n","        print(\"*********\")\n","        print(\"Missing:\")\n","        print(\"*********\")\n","        display(df.isnull().sum() / df.shape[0] * 100)\n","        print()\n","\n","    if debug_mode:\n","        print(\"************\")\n","        print(\"Duplicates:\")\n","        print(\"************\")\n","        print(df.shape[0] - df.nunique())\n","        print()\n","\n","    if debug_mode or check_scaling:\n","        print(\"**********\")\n","        print(\"Describe:\")\n","        print(\"**********\")\n","        display(df.describe())\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"zsHA0J5qBzGX"},"source":["### **Visualize mode**"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"aO1f5X1fAgrf","executionInfo":{"status":"ok","timestamp":1756414594836,"user_tz":-180,"elapsed":57,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def visualize(df):\n","    global NUMERICAL_FEATURES\n","\n","    if visualize_mode:\n","        columns = df.columns\n","        n_cols = 4 # number of plots per row\n","        n_rows = -(-len(columns) // n_cols)\n","\n","        plt.figure(figsize=(4 * n_cols, 3 * n_rows))\n","\n","        for i, column in enumerate(columns, 1):\n","            plt.subplot(n_rows, n_cols, i)\n","\n","            if pd.api.types.is_numeric_dtype(df[column]):\n","                # Histogram for numeric data\n","                plt.hist(df[column].dropna(), bins=40, color=\"deeppink\", edgecolor=\"black\")\n","                plt.xlabel(column)\n","                plt.ylabel(\"Count\")\n","                plt.title(f\"Histogram of {column}\")\n","\n","            else:\n","                # Bar plot for categorical data\n","                df[column].value_counts().plot(kind=\"bar\", color=\"deeppink\", edgecolor=\"black\")\n","                plt.xlabel(column)\n","                plt.ylabel(\"Count\")\n","                plt.title(f\"Bar Plot of {column}\")\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","    if visualize_mode or check_outliers:\n","        if not NUMERICAL_FEATURES:\n","            NUMERICAL_FEATURES = df.select_dtypes(include=\"number\").columns\n","\n","        plt.figure(figsize=(15, 8))\n","        df[NUMERICAL_FEATURES].boxplot()\n","        plt.xticks(rotation=45)\n","        plt.title(\"Boxplots of All Numerical Columns\")\n","        plt.show()\n","\n","    if visualize_mode or check_skewness:\n","        sns.set_style(\"darkgrid\")\n","\n","        NUMERICAL_FEATURES = df.select_dtypes(include=\"number\").columns\n","\n","        plt.figure(figsize=(15, 12))\n","        for idx, feature in enumerate(NUMERICAL_FEATURES, 1):\n","            plt.subplot(5, 4, idx)\n","            sns.histplot(df[feature], kde=True)\n","            plt.title(f\"{feature} | Skewness: {round(df[feature].skew(), 2)}\")\n","\n","        plt.tight_layout()\n","        plt.show()\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"9Fbg27pqB0rB"},"source":["### **Enforce numeric data type**"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"SQFGYdYkAi1w","executionInfo":{"status":"ok","timestamp":1756414594894,"user_tz":-180,"elapsed":63,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def enforce(df, columns):\n","    df[columns] = df[columns].astype(int)\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"8KFJfhbmB5Ya"},"source":["### **Handle missing values**"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"s1ud0kxdAyzX","executionInfo":{"status":"ok","timestamp":1756414594897,"user_tz":-180,"elapsed":5,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def handle_missing(df):\n","\n","    for col in remove_missing:\n","        df = df.dropna(subset=[col])\n","    for col in fill_mean:\n","        df[col] = df[col].fillna(df[col].mean())\n","    for col in fill_median:\n","        df[col] = df[col].fillna(df[col].median())\n","    for col in fill_mode:\n","        df[col] = df[col].fillna(df[col].mode()[0])\n","    for col in fill_ffill:\n","        df[col] = df[col].fillna(method='ffill')\n","    for col in fill_bfill:\n","        df[col] = df[col].fillna(method='bfill')\n","    for col in fill_constant:\n","        df[col] = df[col].fillna(fill_constant_value)\n","\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"TqhLySDMB7cp"},"source":["### **Handle outliers**"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"lm95C4LuAyaI","executionInfo":{"status":"ok","timestamp":1756414594901,"user_tz":-180,"elapsed":2,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def handle_outliers(df):\n","    z = np.abs(stats.zscore(df[outliers_zscore], nan_policy='omit'))\n","    df = df[(z < outliers_zscore_threshold).all(axis=1)]\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"vveSCRbbB8ya"},"source":["### **Handle data scaling**"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"pFSbP2ZVAxmg","executionInfo":{"status":"ok","timestamp":1756414594905,"user_tz":-180,"elapsed":2,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def scale(command, x_train, x_test):\n","    # All these flags are lists that include features to apply the process on\n","\n","    if standard_scale:\n","        sc = StandardScaler()\n","        x_train = sc.fit_transform(x_train)\n","        x_test = sc.transform(x_test)\n","\n","    if min_max_scale:\n","        MinMax = MinMaxScaler()\n","        x_train = MinMax.fit_transform(x_train)\n","        x_test = MinMax.transform(x_test)\n","\n","    if robust_scale:\n","        rb = RobustScaler()\n","        x_train = rb.fit_transform(x_train)\n","        x_test = rb.transform(x_test)"]},{"cell_type":"markdown","metadata":{"id":"nXMDtuWKB-ng"},"source":["### **Handle skewness**"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"u31LEDQ2AxD-","executionInfo":{"status":"ok","timestamp":1756414594919,"user_tz":-180,"elapsed":13,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def skew(df):\n","    if skew_power:\n","        pt = PowerTransformer(method='yeo-johnson')\n","        df[skew_power] = pt.fit_transform(df[skew_power])\n","        print(f\"Applied PowerTransformer on {skew_power}\")\n","\n","    if skew_log1p:\n","        for col in skew_log1p:\n","            if (df[col] <= 0).any():\n","                print(f\"Skipping log1p for {col} because it contains negative values.\")\n","                continue\n","            df[col] = np.log1p(df[col])\n","        print(f\"Applied log1p transformation on {skew_log1p}\")\n","\n","    if skew_cbrt:\n","        for col in skew_cbrt:\n","            df[col] = np.cbrt(df[col])\n","        print(f\"Applied Cube Root transformation on {skew_cbrt}\")"]},{"cell_type":"markdown","metadata":{"id":"Z1vWLWVJB_7p"},"source":["### **Encode data**"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"k0HaobZRAwjF","executionInfo":{"status":"ok","timestamp":1756414594924,"user_tz":-180,"elapsed":2,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def encode(df):\n","    if label_encode:\n","        encoder = LabelEncoder()\n","        for feature in label_encode:\n","            df[feature] = encoder.fit_transform(df[feature])\n","\n","    if one_hot_encode:\n","        encoder = OneHotEncoder()\n","        df[one_hot_encode] = encoder.fit_transform(df[one_hot_encode])\n","\n","    if ordinal_encode:\n","        encoder = OrdinalEncoder()\n","        df[ordinal_encode] = encoder.fit_transform(df[ordinal_encode])\n","\n","    return df"]},{"cell_type":"markdown","source":[],"metadata":{"id":"Mqhyook7cHX2"}},{"cell_type":"markdown","metadata":{"id":"TkFWJmjPescw"},"source":["## **Feature engineering**"]},{"cell_type":"markdown","metadata":{"id":"JQ2bvfwxCVr-"},"source":["### **Feature selection**"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"ScC3vr2fskf3","executionInfo":{"status":"ok","timestamp":1756414594927,"user_tz":-180,"elapsed":1,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def feature_selection(df):\n","    print(\"Initializing the feature selection process...\")\n","\n","    if check_correlation or corr_threshold or drop_features:\n","        df = corr(df)\n","\n","    x = df.drop(TARGET, axis=1).values\n","    y = df[TARGET].values\n","\n","    if debug_mode:\n","        display(x)\n","        display(y)\n","\n","    print(\"Features and target have been determined!\")\n","    return x, y"]},{"cell_type":"markdown","metadata":{"id":"6wcDgrGGCBIf"},"source":["### **Correlation**"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"uP0GJPWFAv3I","executionInfo":{"status":"ok","timestamp":1756414594946,"user_tz":-180,"elapsed":11,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def corr(df):\n","    if corr_threshold:\n","        # Drop all features with correlation price less than the value of corr_threshold\n","        corr_matrix = df.corr()\n","        price_corr = corr_matrix[TARGET].abs()\n","        features_to_drop = price_corr[price_corr < corr_threshold].index.tolist()\n","        df = df.drop(features_to_drop, axis=1)\n","        print(f\"Dropped features with correlation less than {corr_threshold}: {features_to_drop}\")\n","\n","    if drop_features: # Drop features in the drop_features list\n","        df = df.drop(drop_features, axis=1)\n","\n","    if check_correlation: # Print the correlation to the target feature\n","        corr_matrix = df.corr()\n","        price_corr = (corr_matrix[TARGET].abs() * 100).sort_values(ascending=False)\n","        print(\"Pearson Correlation Percentage:\\n\", price_corr)\n","\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"qcVDyxM1e0i0"},"source":["## **Models training**"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"JdjnoIUxsnzX","executionInfo":{"status":"ok","timestamp":1756414594947,"user_tz":-180,"elapsed":4,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def split_train_test(x, y):\n","    x_train, x_test, y_train, y_test = train_test_split(\n","        x, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)\n","\n","    print(\"Data has been splitted to training and testing\")\n","    return x_train, x_test, y_train, y_test"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"D-rKMzdcs0wa","executionInfo":{"status":"ok","timestamp":1756414594968,"user_tz":-180,"elapsed":23,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def train_model(x_train, y_train):\n","    trained_models = {}\n","    for name, model in REGRESSION_MODELS.items():\n","        print(f\"Training {name}\")\n","        trained_models[name] = model.fit(x_train, y_train)\n","\n","    print(\"Model has been trained\")\n","    return trained_models"]},{"cell_type":"markdown","metadata":{"id":"eRsYqv-Ce3IG"},"source":["## **Models evaluation**"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"O5onGiUjs2FC","executionInfo":{"status":"ok","timestamp":1756414595006,"user_tz":-180,"elapsed":58,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["\n","def evaluate_all_models(trained_models, X, y, dataset_name):\n","\n","    scores = {}\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Evaluating models on {dataset_name} dataset:\")\n","    print(f\"{'='*60}\")\n","\n","    for name, model in trained_models.items():\n","        y_pred = model.predict(X)\n","        score = r2_score(y, y_pred)\n","        scores[name] = score\n","        print(f\"R² score for {name}: {(score * 100):.4f}%\")\n","\n","    print(f\"{'='*60}\")\n","    return scores"]},{"cell_type":"markdown","metadata":{"id":"_mOBi_lVe5v1"},"source":["## **Model deployment**"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"n50afeuBtI6D","executionInfo":{"status":"ok","timestamp":1756414595014,"user_tz":-180,"elapsed":23,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def load_model(path):\n","    if os.path.exists(path):\n","        print(\"Model has been loaded\")\n","        return joblib.load(path)\n","    else:\n","        raise FileNotFoundError(f\"No model found at {path}\")"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"c1kNmfcbtAgE","executionInfo":{"status":"ok","timestamp":1756414595015,"user_tz":-180,"elapsed":22,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def save_model(model, path):\n","    joblib.dump(model, path)\n","    print(f\"Model has been saved\")"]},{"cell_type":"markdown","metadata":{"id":"xolpg6Lje-pj"},"source":["## **Main**"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"fd1EBJrYyjdW","executionInfo":{"status":"ok","timestamp":1756414595337,"user_tz":-180,"elapsed":342,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}}},"outputs":[],"source":["def run_pipeline():\n","    df = load_data()  # Load data\n","    df = preprocessing(df)  # Apply all preprocessing\n","    x, y = feature_selection(df)\n","\n","    x_train, x_test, y_train, y_test = split_train_test(x, y)\n","\n","    # Train all models\n","    trained_models = train_model(x_train, y_train)\n","\n","    # Evaluate on Training set (R²)\n","    print(\"\\n--- Training Set Performance ---\")\n","    train_scores = {}\n","    for name, model in trained_models.items():\n","        y_pred_train = model.predict(x_train)\n","        score_train = r2_score(y_train, y_pred_train)\n","        train_scores[name] = score_train\n","        print(f\"{name} R² on Training set = {score_train*100:.2f}%\")\n","\n","    # Evaluate on Test set (R²)\n","    print(\"\\n--- Test Set Performance ---\")\n","    test_scores = {}\n","    for name, model in trained_models.items():\n","        y_pred_test = model.predict(x_test)\n","        score_test = r2_score(y_test, y_pred_test)\n","        test_scores[name] = score_test\n","        print(f\"{name} R² on Test set = {score_test*100:.2f}%\")\n","\n","    # Select best model based on Test set\n","    best_model_name = max(test_scores, key=test_scores.get)\n","    best_model = trained_models[best_model_name]\n","    print(f\"\\nBest model based on Test set: {best_model_name} with R² = {test_scores[best_model_name]*100:.2f}%\")\n","\n","    # Save best model\n","    if do_save_model:\n","        save_model(best_model, MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"7KYoHq8HlKMY"},"source":["## **Pipeline runner**"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"gc1PBgOmqS5h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756414594611,"user_tz":-180,"elapsed":86313,"user":{"displayName":"Karimskee","userId":"13948990257632174486"}},"outputId":"bc95cd4f-9c45-4b6d-c83a-6c5e5e8428cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Numerical features have been selected automatically\n","Categorical features have been selected automatically\n","Data has been loaded\n","Initializing the feature selection process...\n","Features and target have been determined!\n","Data has been splitted to training and testing\n","Training LinearRegression\n","Training KNN\n","Training SVR_rbf\n","Training SVR_poly\n","Training SVR_sigmoid\n","Training DecisionTree\n","Training RandomForest\n","Training Bagging\n","Training AdaBoost\n","Training GradientBoosting\n","Training XGBoost\n","Model has been trained\n","\n","--- Training Set Performance ---\n","LinearRegression R² on Training set = 100.00%\n","KNN R² on Training set = 89.64%\n","SVR_rbf R² on Training set = 42.37%\n","SVR_poly R² on Training set = 22.79%\n","SVR_sigmoid R² on Training set = -2567982.64%\n","DecisionTree R² on Training set = 99.80%\n","RandomForest R² on Training set = 99.93%\n","Bagging R² on Training set = 99.90%\n","AdaBoost R² on Training set = 100.00%\n","GradientBoosting R² on Training set = 99.99%\n","XGBoost R² on Training set = 99.97%\n","\n","--- Test Set Performance ---\n","LinearRegression R² on Test set = 100.00%\n","KNN R² on Test set = 56.82%\n","SVR_rbf R² on Test set = 23.77%\n","SVR_poly R² on Test set = 12.35%\n","SVR_sigmoid R² on Test set = -1204171.10%\n","DecisionTree R² on Test set = 84.03%\n","RandomForest R² on Test set = 84.03%\n","Bagging R² on Test set = 83.85%\n","AdaBoost R² on Test set = 84.14%\n","GradientBoosting R² on Test set = 86.83%\n","XGBoost R² on Test set = 78.96%\n","\n","Best model based on Test set: LinearRegression with R² = 100.00%\n"]}],"source":["run_pipeline()"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["f1_1-XLM_TB4","j082OXYBcTqW","GGY8WfgLerAP","knBtIcqXfIj_","CQOo22ejBw2B","zsHA0J5qBzGX","9Fbg27pqB0rB","8KFJfhbmB5Ya","TqhLySDMB7cp","vveSCRbbB8ya","nXMDtuWKB-ng","Z1vWLWVJB_7p","JQ2bvfwxCVr-","6wcDgrGGCBIf","qcVDyxM1e0i0","eRsYqv-Ce3IG","_mOBi_lVe5v1","xolpg6Lje-pj"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}